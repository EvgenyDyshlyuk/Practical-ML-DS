{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install RISE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MATHEMATICS AND PROGRAMMING\n",
    "___\n",
    "### LINEAR ALGEBRA \n",
    "### VECTORS AND MATRICES 101 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Author: \n",
    "#### Teaching Date: \n",
    "#### Contents:\n",
    "- [Contents](#MATHEMATICS-AND-PROGRAMMING)\n",
    " - [Vectors - why should we study this?](#WHAT-IS-A-VECTOR?)\n",
    " - [Vector Addition](#)\n",
    " - [Vector Subtraction](#)\n",
    " - [Vector Multiplication](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WHAT IS A VECTOR?\n",
    "___\n",
    "\n",
    "<p> If I told you I was walking to the shops at 3 mph then this is me telling you my speed. Speed is a scalar value. If instead I had told you I am walking East to the shops at 3 mph. I've just given you my speed <b>and</b> direction. Hence, you now know my velocity. Velocity is a vector. </p>\n",
    "\n",
    "<p> This section is all about vectors and understanding their properties. Vectors always come into a large part of data science and deep learning and so understanding them makes the more complicated things alot simpler!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What do they look like and why study about vectors?: \n",
    "\n",
    "* Vectors are usually represented as: $\\vec{V}\\$ \n",
    "* Vector maths comes up everywhere: KNNs, PCA, LDA, SVMs (concepts we will talk about more in the data science part of the course). But ass ypou can see understanding the maths is essential to really understand what's going on here. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vector Addition\n",
    "\n",
    "* Let's start with a simple vector: $\\vec{A}$.\n",
    "\n",
    "\n",
    "* Let's add $\\vec{B}\\$ to this.\n",
    "\n",
    "\n",
    "* $\\vec{A}= \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} , \\vec{B}\\ = \\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "* Therefore, $\\vec{A}\\ +  \\vec{B}= \\begin{bmatrix} (1+0) \\\\ (3+2) \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 5 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "* Or more generally $A = \\begin{bmatrix} a_1 \\\\ a_2 \\end{bmatrix} , B =  \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} therefore \\space \\vec{A}\\ + \\vec{B}\\ = \\begin{bmatrix} a_1 + b_1 \\\\ a_2 + b_2 \\end{bmatrix} $. \n",
    "\n",
    "<b>get someone to prettify this... add in a diagram on a R^2 showing the 2 vectors being added</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Vector Subtraction\n",
    "\n",
    "* Similar to matrix subtraction you can subtract one vector from another \n",
    "\n",
    "\n",
    "* Using $\\vec{A}\\ and \\space \\vec{B}$ as examples we will subtract one from another\n",
    "\n",
    "\n",
    "* Generally, $\\vec{A}\\ - \\vec{B}\\ = \\begin{bmatrix} a_1 - b_1 \\\\ a_2 - b_2 \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "* Therefore, $\\vec{A}\\ -  \\vec{B}= \\begin{bmatrix} (1-0) \\\\ (3-2) \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "<b>get someone to prettify and add in diagram showing the subtraction </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Vector Multiplication: Vectors $x$ Scalars\n",
    "\n",
    "<b>Draw a 2D graph showing A and 2A </b>\n",
    "\n",
    "* Sometimes you need to multiply a vector by a scalar. For example you might have a value which is 3 times that of  $\\vec{A}$\n",
    "\n",
    "* So, $ 3 \\vec{A} =  \\begin{bmatrix} 3  x  a_1 \\\\ 3  x  a_2 \\end{bmatrix} => \\begin{bmatrix} (3  x  1) \\\\ (3  x  3) \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 9 \\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Vector Multiplication: Vectors $x$ Vectors (dot product)\n",
    "\n",
    "<b>Draw 2 vectors on a graph and show how you use trig to find projection of one on another</b>\n",
    "\n",
    "* The dot product is a way of understanding how similar 2 vectors are \n",
    "\n",
    "\n",
    "* The formula for the dot product of 2 vectors is: $ \\vec{A} \\cdot  \\vec{B} = |{\\vec{A}}|\\cdot|{\\vec{B}}| \\cos(\\theta) $ \n",
    "\n",
    "\n",
    "* What does this allow you to do? Well in feaatur vectors we can determine the similarity between 2 vectors. Believe it or not, this is how Amazon used to recommend similar products for you to buy! \n",
    "\n",
    "\n",
    "* Let's talk through this. Let's say I've recently bought some pens from Amazon. How could the dot product help to recommend me similar products? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Vector Magnitude to determine the length\n",
    "\n",
    "- You often need to calculate the magnitude of a vector\n",
    "\n",
    "- You do this by $sqroot((x_2 - x_1)^2 + (y_2 - y_1)^2 ... + (x_n - x_(n-1))^2)$\n",
    "\n",
    "- Measuring the similarity between 2 vectors is an essential part of machine learning and is used in a lot of dat science\n",
    "\n",
    "- <b> Diagram showing calcualtion using pythagoras </b>\n",
    "- <b> Someone to help tidy up the above formula </b>\n",
    "\n",
    "#### Matrix multiplication \n",
    "\n",
    "- Vector * Matrix multiplication\n",
    "- Matrix * Matrix \n",
    "- Weights, coefficients and features in linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the amazon recommendation system.... say whaaat?!\n",
    "\n",
    "- We will cover in the how we do this in python later, but for now, let's just watch and see how the dot product allows use to identify similar products! \n",
    "\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "average_frequency = [440,352,1053,153,3002]\n",
    "loudness = [-6,-3,-4,-2, -4]\n",
    "duration = [3.4, 9.2, 1.2, 20.9, 5.1]\n",
    "df = pd.DataFrame({\n",
    "    'average':average,\n",
    "    'loudness':loudness,\n",
    "    'duration':duration\n",
    "})\n",
    "def standardise(v):\n",
    "    print(sum(v))\n",
    "    print(len(v))\n",
    "    mean = sum(v)/len(v)\n",
    "    print(mean)\n",
    "    std_dev = math.sqrt((1/len(v) * sum([ (x_i - mean)**2 for x_i in v])))\n",
    "    print(std_dev)\n",
    "    return [(x_i - mean)/std_dev for x_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
