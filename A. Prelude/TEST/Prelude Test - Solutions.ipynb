{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude Test\n",
    "\n",
    "This test has been created to ensure a candidate has adequete knowledge in Linear Algebra, Calculus and Probability. Some concepts may be new to a candidate - but we encourage the use of Googling and looking at external resources in order to gain a stronger understanding and solve the problem. \n",
    "\n",
    "The Linear Algebra section of this test is heavily inspired from: https://www.researchgate.net/publication/246546380_Singular_Value_Decomposition_Tutorial. Feel free to use it as a reference if you need description/clarification of a concept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vector object\n",
    "\n",
    "Add methods to this object which: \n",
    "1. Calculate the length/norm of a vector\n",
    "2. Scalar multiplies a vector\n",
    "3. Returns the unit vector of the vector\n",
    "\n",
    "Until permitted, the ONLY Numpy method you should use is np.array(). However, the use of the inbuilt math library is fully permitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vector():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "        \n",
    "    def scalar_multiply(self, scalar):\n",
    "        return scalar * self.vector\n",
    "    \n",
    "    def length(self):\n",
    "        return math.sqrt(sum([elem**2 for elem in self.vector]))\n",
    "    \n",
    "    def unit_vector(self):\n",
    "        return self.vector / self.length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.  6.  1.5 3. ]\n",
      "5.0\n",
      "[0.4 0.8 0.2 0.4]\n"
     ]
    }
   ],
   "source": [
    "v_ = np.array([2,4,1,2])\n",
    "vector = Vector(v_)\n",
    "print(vector.scalar_multiply(1.5))\n",
    "print(vector.length())\n",
    "print(vector.unit_vector())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A static method...\n",
    "is a method which is run against the class itself, rather than an instance of the class. [More information can be found here](https://www.journaldev.com/18722/python-static-method).\n",
    "\n",
    "Copy the vector class you defined above and add static methods which facilitate:\n",
    "1. Adding two vectors\n",
    "2. Calculating the inner product of two vectors\n",
    "3. Checking whether two vectors are orthogonal to each other (returns a boolean - true if orthogonal, false otherwise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vector():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "        \n",
    "    def scalar_multiply(self, scalar):\n",
    "        return scalar * self.vector\n",
    "    \n",
    "    def length(self):\n",
    "        return math.sqrt(sum([elem**2 for elem in self.vector]))\n",
    "    \n",
    "    def unit_vector(self):\n",
    "        return self.vector / self.length()\n",
    "    \n",
    "    @staticmethod\n",
    "    def add(vec1, vec2):\n",
    "        # Do NOT just directly add the vectors together using the \"+\" operator\n",
    "        added_vector = []\n",
    "        for u, v in zip(vec1, vec2):\n",
    "            added_vector.append(u + v)\n",
    "        return np.array(added_vector)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def inner(vec1, vec2):\n",
    "        inner = 0\n",
    "        for u, v in zip(vec1, vec2):\n",
    "            inner += u*v\n",
    "        return inner\n",
    "    \n",
    "    @staticmethod\n",
    "    def orthogonal(vec1, vec2):\n",
    "        if Vector.inner(vec1, vec2) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 -5  2  6]\n",
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "vec1 = np.array([2,1,-2,4])\n",
    "vec2 = np.array([3,-6,4,2])\n",
    "\n",
    "print(Vector.add(vec1, vec2))\n",
    "print(Vector.inner(vec1, vec2))\n",
    "print(Vector.orthogonal(vec1, vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function which multiplies two matricies together\n",
    "Use nested for loops to implement the algorithm. Comment what the algorithm/each for loop is doing in as much detail as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(mat1, mat2):\n",
    "    mat1_rows = mat1.shape[0]\n",
    "    mat1_cols = mat1.shape[1]\n",
    "    mat2_rows = mat2.shape[0]\n",
    "    mat2_cols = mat2.shape[1]\n",
    "    \n",
    "    assert mat1_cols == mat2_rows, \"Incompatible shapes between the two matrices. Mat1 cols should be the same as Mat2 rows\"\n",
    "    print(\"New Matrix shape is going to be: [{} x {}]\".format(mat1_rows, mat2_cols))\n",
    "    \n",
    "    result = np.zeros((mat1_rows, mat2_cols))\n",
    "    \n",
    "    ## Add matrix multiplication code here\n",
    "    for m1_row in range(mat1.shape[0]):\n",
    "        for m2_col in range(mat2.shape[1]):\n",
    "            for m2_row in range(mat2.shape[0]):\n",
    "                result[m1_row][m2_col] += mat1[m1_row][m2_row] * mat2[m2_row][m2_col]\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Matrix shape is going to be: [3 x 4]\n",
      "[[114. 160.  60.  27.]\n",
      " [ 74.  97.  73.  14.]\n",
      " [119. 157. 112.  23.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray([[12,7,3],\n",
    "    [4 ,5,6],\n",
    "    [7 ,8,9]])\n",
    "# 3x4 matrix\n",
    "Y = np.asarray([[5,8,1,2],\n",
    "    [6,7,3,0],\n",
    "    [4,5,9,1]])\n",
    "\n",
    "print(matmul(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinants, Eigenvalues and Eigenvectors\n",
    "### By hand...\n",
    "Calculate the determinant of the following two matricies:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "6 & 2 \\\\\n",
    "3 & 2\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "2 & -3 & 4 \\\\\n",
    "1 & 1 & -8 \\\\\n",
    "3 & 2 & 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Calculate the eigenvalues and eigenvectors of the matrix:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "3 & -2 \\\\\n",
    "-6 & 7\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Please show your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "In this part of the assessment, we will run you through an implementation of an algorithm known as Singular Value Decomposition (SVD). If this is your first introduction to this algorithm, we highly recommend [reading the tutorial](https://www.researchgate.net/publication/246546380_Singular_Value_Decomposition_Tutorial) linked at the top of the document.\n",
    "\n",
    "SVD is given by the formula:\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{USV}^T \\\\\n",
    "A \\in \\mathbb{R}^{m \\times n}, U \\in \\mathbb{R}^{m \\times m}, S \\in \\mathbb{R}^{m \\times n}, V \\in \\mathbb{R}^{n \\times n}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{U}^T\\mathbf{U} = \\mathbf{I}$, $\\mathbf{V}^T\\mathbf{V} = \\mathbf{I}$. \n",
    "- The columns of $\\mathbf{U}$ are orthonormal eigenvectors of $\\mathbf{AA}^T$\n",
    "- The columns of $\\mathbf{V}$ are orthonormal eigenvectors of $\\mathbf{A}^T\\mathbf{A}$\n",
    "- $\\mathbf{S}$ is a diagonal matrix containing the square roots of eigenvalues from $\\mathbf{U}$ or $\\mathbf{V}$ in descending order.\n",
    "\n",
    "Full use of Numpy is allowed for this section (apart from the SVD method). You will have search around to identify which methods are required to be used/called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTION. DO NOT MODIFY THIS CELL\n",
    "def reorder_eig_vectors(eig_tuple):\n",
    "    eig_values, eig_vectors = eig_tuple\n",
    "    idx = eig_values.argsort()[::-1]\n",
    "    eig_values = eig_values[idx]\n",
    "    eig_vectors = eig_vectors[:, idx]\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[11  1]\n [ 1 11]]\n[12. 10.] [[ 0.70710678 -0.70710678]\n [ 0.70710678  0.70710678]]\n"
    }
   ],
   "source": [
    "A = np.array([[3,1,1],[-1,3,1]])\n",
    "\n",
    "## Find U (i.e. calculate AA^T)\n",
    "U_ = np.matmul(A, A.T)\n",
    "print(U_)\n",
    "\n",
    "## Calculate the eigenvectors/eigenvalues of U\n",
    "U = np.linalg.eig(U_)\n",
    "\n",
    "## Use the helper function to reorder the eigens\n",
    "U_eig_values, U_eig_vectors = reorder_eig_vectors(U)\n",
    "print(U_eig_values, U_eig_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Find V (i.e. calculate A^TA)\n",
    "V_ = np.matmul(A.T, A)\n",
    "\n",
    "## Calculate the eigenvectors/eigenvalues of U\n",
    "V = np.linalg.eig(V_)\n",
    "\n",
    "## Use the helper function to reorder the eigens\n",
    "V_eig_values, V_eig_vectors = reorder_eig_vectors(V)\n",
    "\n",
    "## Transpose the V eigen vectors\n",
    "V_eig_vectors = V_eig_vectors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialise S as an m x n matrix\n",
    "m = len(U[0])\n",
    "n = len(V[0])\n",
    "S = np.zeros((m, n))\n",
    "\n",
    "## Populate the diagonal of S with the square root of the non-zero eigenvalues from U and V.\n",
    "## The diagonal should be filled in decending order (from largest to smallest) of these eigenvalues.\n",
    "np.fill_diagonal(S, np.sqrt(U_eig_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 3.  1.  1.]\n [-1.  3.  1.]]\n"
    }
   ],
   "source": [
    "## Apply the SVD formula: A = USV.T\n",
    "first_part = U_eig_vectors.dot(S)\n",
    "reconstructed_A = first_part.dot(V_eig_vectors)\n",
    "\n",
    "# DON'T CHANGE THIS LINE. The final answer you obtain should be the same as the original A matrix.\n",
    "reconstructed_A = -1 * reconstructed_A[[1,0]]\n",
    "print(reconstructed_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus\n",
    "\n",
    "Understanding the chain rule is essential to understanding how gradient based optimization, a technique will introduce later in the course, works. Here, we test two things:\n",
    "- We ask you to work through an example of applying the chain rule\n",
    "- We ask you to draw a tree-diagram for an algebraic derivative.\n",
    "\n",
    "Please provide your answers by hand\n",
    "\n",
    "\n",
    "Given that $z = f(x, y)$ where $x = g(t), y = h(t)$, the derivative of $z$ w.r.t. $t$ is given by:\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dt} = \\frac{\\partial f}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial f}{\\partial y}\\frac{dy}{dt}\n",
    "$$\n",
    "\n",
    "1. <b>Let $z = xe^{xy}, x=t^2, y=t^{-1}$. Using the above formula, find $\\frac{dz}{dt}$. You may leave your answer in terms of $x, y$ and $t$.</b>\n",
    "\n",
    "\n",
    "Given that $z = f(x, y)$ where $x = g(s,t), \\; y = h(s,t)$, the partial derivatives $\\frac{\\partial z}{\\partial s}$ and $\\frac{\\partial z}{\\partial t}$ are given by: \n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\\\\n",
    "\\frac{\\partial z}{\\partial s} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial s} + \\frac{\\partial f}{\\partial y}\\frac{\\partial y}{\\partial s} \\\\\n",
    "\\frac{\\partial z}{\\partial t} = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial t} + \\frac{\\partial f}{\\partial y}\\frac{\\partial y}{\\partial t}\n",
    "$$\n",
    "\n",
    "We can represent the partial derivatives in a tree-diagram as follows:\n",
    "\n",
    "![partial_z](images\\partial_z.png)\n",
    "\n",
    "Similarly, if we are given $w = f(x,y,z),\\; x=g_1(t),\\; y=g_2(t),\\; z=g_3(t)$, the tree-diagram, and derivative of $w$ w.r.t $t$ (i.e. $\\frac{dw}{dt}$) is given by:\n",
    "\n",
    "![partial_w](images\\partial_w.png)\n",
    "$$\n",
    "\\frac{dw}{dt} = \\frac{\\partial f}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial f}{\\partial y}\\frac{dy}{dt} + \\frac{\\partial f}{\\partial z}\\frac{dz}{dt}\n",
    "$$\n",
    "\n",
    "2. <b>Draw the tree-diagram and find the partial derivative $\\frac{\\partial w}{\\partial r}$ given $w = f(x,y,z),\\; x=g_1(s,t,r),\\; y=g_2(s,t,r),\\; z=g_3(s,t,r)$</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "In machine learning, we tend to work with many random variables.\n",
    "\n",
    "By hand (or in a document), **define and provide examples** of the following concepts:\n",
    "\n",
    "1. Joint probability\n",
    "2. Marginal probability\n",
    "3. Conditional probability\n",
    "4. Furthermore, using the chain rule of probability, rewrite the following equation in terms of conditional probabilities:\n",
    "$$\n",
    "p(x_1, x_2, x_3, x_4)\n",
    "$$\n",
    "\n",
    "The general chain rule is given by:\n",
    "$$\n",
    "p(x_1, ..., x_n) = \\prod_i^n p(x_i | x_1, ..., x_{i-1}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}